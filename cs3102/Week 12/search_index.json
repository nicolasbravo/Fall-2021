[["difficulty-of-functions.html", "Week 12 CS 3102 1 “Difficulty” of Functions 1.1 Notions of function “difficulty” 1.2 Larger inputs = more time", " Week 12 CS 3102 Nico Bravo 1 “Difficulty” of Functions So far, we have discussed what is possible/not possible Next, we are going to talk about how we can measure efficiency with Turing machines. 1.1 Notions of function “difficulty” Here is one way we can say “how hard is it to implement this function?”. This is because we can say \"how difficult is it to compute \\(f\\) by saying how hard it is to implement the function. Can an algorithm for function \\(f\\) be implemented using this computing model? NAND-CIRC: answer is yes iff \\(f\\) is finite FSA: answer is yes if function doesn’t require memory TM: answer is no for \\(HALT_{TM}\\), \\(A_{TM}\\), etc How efficient is an algorithm for function \\(f\\) implemented using this computing model? NAND-CIRC How many gates? What circuit depth? FSA we never discussed TM How many transitions are required (time)? How many tape cells are required (space)? Whenever we are looking for efficiency, we are always counting. This includes the time or space required. 1.2 Larger inputs = more time Run time is not measured by a number, but a function Since Turing machines will be implementing infinite functions (unbounded input), as the TM gets larger and larger input, the TM will require more time to compute the output for the input. How much larger is the number of steps? We count them as a function of the input size (interesting in seeing how they relate) Running time: \\(T(n)\\) is a function mapping naturals to naturals. We say \\(F: \\{0,1\\}^* \\rightarrow \\{0,1\\}^*\\) is computable in \\(T(n)\\) time if there exists a Turing machine \\(M\\) such that for every large \\(n\\) and every input \\(x \\in \\{0,1\\}^n\\), \\(M\\) halts after at most \\(T(n)\\) steps and outputs \\(F(x)\\). \\(TIME(T(n))\\) represents the set of boolean functions computable in \\(T(n)\\) time. "],["ram-model.html", "2 RAM Model 2.1 Different computing Models may have Different Running Times", " 2 RAM Model 2.1 Different computing Models may have Different Running Times For example, AON is more efficient than NAND. 2.1.1 TM ruins our concept of how computers really work. A Turing machine uses tapes and can only visit a neighboring cell from the current one A long time ago, a tape was probably a reasonable memory model But this would require us to look at all the cells in between where we are and where we want to look Nowadays, we use flash memory We can look up two locations without visiting all locations between “Random” access memory (RAM) In constant time, given an address, we look up the address… instead of looking through all the addresses in between 2.1.2 RAM Machine We can go directly to a certain index in the tape To transition: Have a second tape to keep track of the current location (increment each time we move right, decrement for left) Have a third tape to record the target location Move until the two tapes match (maybe we need another tape to do this?) An important observation to make is that a tape-machine takes more steps than a RAM machine If a RAM-TM computes \\(f\\) in \\(T(n)\\) time, a tape TM can compute \\(f\\) in \\(T(n)^4\\) time "],["shortest-and-longest-paths.html", "3 Shortest and Longest Paths 3.1 Finding Running Times 3.2 Review of Graphs 3.3 Shortest Path in a graph 3.4 Longest Path in a graph", " 3 Shortest and Longest Paths 3.1 Finding Running Times We are going to be looking at four things this lecture. They are divided into pairs. The first pair are the shortest and longest paths in a graph: Shortest Path in a graph Given two nodes, what is the shortest path in terms of number of hops between the nodes Longest Path in a graph Same problem, but longest instead of shortest The next problems are called “satisfyability problems,” where we are given boolean expressions and we want to know whether we can assign true or false values to some variables to make the whole expression true: 3SAT 2SAT 3.2 Review of Graphs Defined by a pair of sets \\(G = (V,E)\\) where \\(V =\\) list of vertices/nodes and \\(E =\\) ordered pairs of edges (ordered = directed or unordered = undirected graphs). If arrows are drawn, then they are ordered. For weighted graphs, \\(w(e) =\\) the weight of edge \\(e\\). There are a couple ways to display the graphs. 3.2.1 Adjacency List Representation Two nodes are adjacent if they share an edge. This is a list which displays nodes and their adjacent nodes. This is one way to show the graph. ## A B C D E F G H I ## 1 B A A C B C E E G ## 2 C C B E D D F G H ## 3 &lt;NA&gt; E D F G G H I &lt;NA&gt; ## 4 &lt;NA&gt; &lt;NA&gt; F &lt;NA&gt; H &lt;NA&gt; I &lt;NA&gt; &lt;NA&gt; Trade offs: Space Time to list neighbors Time to check edge (A,B) 3.2.2 Adjacency Matrix Representation Two nodes are adjacent if they share an edge. This is a matrix which displays nodes and their adjacent nodes (either true or false). This is another way to show the graph. ## A B C D E F G H I ## A 0 1 1 0 0 0 0 0 0 ## B 1 0 1 0 1 0 0 0 0 ## C 1 1 0 1 0 1 0 0 0 ## D 0 0 1 0 1 1 0 0 0 ## E 0 1 0 1 0 0 1 1 0 ## F 0 0 1 1 0 0 1 0 0 ## G 0 0 0 0 1 1 0 1 1 ## H 0 0 0 0 1 0 1 0 1 ## I 0 0 0 0 0 0 1 1 0 Trade offs: Space Time to list neighbors Time to check edge (A,B) 3.2.3 Paths Paths are a sequence of nodes \\((v_1,v_2,\\dots,v_k)\\) such that \\(\\forall 1\\leq i \\leq k-1,(v_i,v_{i+1}) \\in E\\) Simple path: A path in which each node appears at most once Cycle: A path of \\(&gt;2\\) nodes in which \\(v_1 = v_k\\) 3.3 Shortest Path in a graph Given an unweighted graph, start node \\(s\\), and an end node \\(t\\), how long is the shortest path from \\(s\\) to \\(t\\)? Input: Graph Start End Output: Number (length) We only care about the number of hops, if there are weighted edges we don’t care about those. This is a reasonably easy algorithm: we can use “breadth-first search.” Start with start node “Ripple” outward until you find the end node Here is some pseudocode: keep a queue Q of nodes #all of our nodes are here hops = 0 Q.enqueue(s,hops) #add start node While Q is not empty and v != t: #until we run out of nodes to visit v,hops = Q.dequeue() #remove something from the queue for each unvisited u in V such that (v,u) is in E: Q.enqueue(u,hops+1) #add all unvisited neighbors to queue This is roughly linear-time and therefore efficient. 3.4 Longest Path in a graph This is a minor change from the previous algorithm, where we are instead looking for the longest simple path between \\(s\\) and \\(t\\). This small change makes it a much harder problem to solve. One way we can do this is enumerating all possible sequences of nodes There will \\((n-1)!\\) of these Check if every one of these is a paths Print the length of the longest one This is \\(n!\\) running time, so VERY SLOW! But we don’t really know how to make this substantially faster than this brute force. This is an inefficient algorithm. "],["satisfiability.html", "4 Satisfiability 4.1 3-CNF 4.2 3-SAT 4.3 2-SAT", " 4 Satisfiability Before we can talk about the other two problems, we need to define something. 4.1 3-CNF Conjunctive Normal Form (CNF, format for writing down expression) formula: Logical AND (\\(\\wedge\\)) of clauses That’s what Conjunctive means Each group/clause is separated by ands Each clause being an OR (\\(\\vee\\)) of variables In each group/clause, can only have ors 3-CNF: Each clause has 3 variables Example of a clause: \\((x \\vee y \\vee z)\\) Example of variables: \\(x, y, z\\) Example of CNF: \\((x \\vee y \\vee z) \\wedge (x \\vee \\overline{y} \\vee y) \\wedge (u \\vee y \\vee \\overline{z})\\) We want to know whether if we assigned true or false to any of these variables, there is a possible combination where we can make the whole formula return true. Because each clause is composed of 3 variables, we only need to check if one of the three variables in each clause is true If so, the entire statement comes out as true If any clause is false, the entire formula is false 4.2 3-SAT The 3 means that we are receiving a formula in 3-CNF format. Given a 3-CNF formula (logical AND of clauses, each an OR of 3 variables), is there an assignment of true or false to each variable to make the entire formula true? An example of a formula and assignment that return true are as follows. Since every one of the clauses in this formula have at least one true variable, the entire formula returns as true: Formula: \\((x \\vee y \\vee z) \\wedge (x \\vee \\overline{y} \\vee y) \\wedge (u \\vee y \\vee \\overline{z}) \\wedge (z \\vee \\overline{x} \\vee u) \\wedge (\\overline{x} \\vee \\overline{y} \\vee \\overline{z})\\) Assignment: \\(x = true\\) \\(y = false\\) \\(z = false\\) \\(u = true\\) 4.2.1 3-SAT Algorithm Given a 3-CNF formula with \\(n\\) variables and \\(m\\) clauses, Try all combinations of true/false Check to see if any combinations evaluate to true This running time is \\(2^n\\) because there are this many combinations. 4.3 2-SAT Given a 2-CNF formula (logical AND of clauses, each an OR of 3 variables), is there an assignment of true or false to each variable to make the entire formula true? An example of a formula and assignment that return true are as follows. Since every one of the clauses in this formula have at least one true variable, the entire formula returns as true: Formula: \\((x \\vee y) \\wedge (x \\vee \\overline{y}) \\wedge (y \\vee \\overline{z}) \\wedge (z \\vee u) \\wedge (\\overline{y} \\vee \\overline{z})\\) Assignment: \\(x = true\\) \\(y = false\\) \\(z = false\\) \\(u = true\\) 4.3.1 2-SAT Algorithm We can use the algorithm used for 3-SAT, which has a runtime of \\(2^n\\) Or, we can use another algorithm, which has a runtime of \\(n^3\\)… We can convert the formula into an “implication graph” where if one variable of two in a clause is false, the other must be true. This causes us to be able to make a graph where we can list variables that require others to be true and link them together (\\(\\overline{z}\\) requires \\(u\\), \\(z\\) requires \\(\\overline{y}\\) which requires \\(x\\), etc). This allows us to create a cycle of what each variable needs to be for the entire formula to work. This cycle can then show us that, if a variable requires \\(y\\) to be true and also \\(y\\) to be false to work, for example, that assignment will never be satisfiable. 4.3.2 Unsatisfyable Example Formula: \\((x \\vee y) \\wedge (\\overline{x} \\vee y) \\wedge (x \\vee \\overline{y}) \\wedge (\\overline{x} \\vee \\overline{y})\\) Implications: \\((x \\vee y)\\) If \\(x\\) is false, \\(y\\) must be true \\((x \\vee \\overline{y})\\) If \\(y\\) is true, \\(x\\) must be true \\((\\overline{x} \\vee \\overline{y})\\) If \\(x\\) is true, \\(y\\) must be false Now we created a cycle that has both \\(x\\) and \\(\\overline{x}\\), so we are not going to be able to come up with an assignment that will satisfy this formula. Now we have a trick where we can make a graph with \\(n\\) nodes and \\(2m\\) edges (2 edges per clause, \\(m\\) clauses). Then, we can just do a breadth-first search to find whether there will be a variable and its negation, and this will take \\(n + 2m\\), so this is efficient. 4.3.3 Polynomial Time vs Exponential Time Polynomial Time: \\(P = \\bigcup_{c \\in \\{1,2,3,\\dots\\}} n^c\\) Faster Exponential Time: \\(EXP = \\bigcup_{c \\in \\{1,2,3\\dots\\}} 2^{n^c}\\) Slower Weird pattern Most “natural” problems are either done in small degree polynomial (\\(n^2,n^3\\)) or exponential time (\\(2^n,n!\\)) "],["tractable-and-intractable-problems.html", "5 Tractable and Intractable Problems 5.1 Tractability", " 5 Tractable and Intractable Problems Running time is essentially the number of steps needed for an input Not a number, but a function that takes the input as an argument \\(TIME(n)\\) is a complexity class that is the set of all functions where \\(T(n) = n\\) 5.1 Tractability Tractable: Feasible to solve in the “real world” Intractable: Infeasible to solve in the “real world” Whether a problem is considered “tractable” or “intractable” depends on the use case Tractable = polynomial time Intractable = exponential time "],["polynomial-time-reductions.html", "6 Polynomial Time Reductions 6.1 Using Reductions for Efficiency 6.2 Polynomial Time Reductions 6.3 Transitivity of Polynomial Time Reductions 6.4 Procedure for showing \\(A \\leq_p B\\)", " 6 Polynomial Time Reductions When we turned the 2-SAT formula into a graph, we reduced 2-SAT to cycle finding, where we could then use breadth-first search. This is a reduction like we did last week. Given some 2-SAT formula We created an implication graph Then we saw if there was a cycle And solved using Breadth First Search Where a solution exists if and only if there is no such cycle 6.1 Using Reductions for Efficiency Show how an “efficient” algorithm for \\(F\\) could be used to build an “efficient” algorithm for \\(H\\) If we had a way to solve \\(F\\): That solution, with our reduction, “completes” an “efficient” solution to \\(H\\) 2 possible conclusions: If there is an “efficient” solution for \\(F\\) then there is an “efficient” solution for \\(H\\) If there is not an “efficient” solution for \\(H\\) then there can’t be an “efficient” solution for \\(F\\) The reduction must be “efficient” 6.2 Polynomial Time Reductions “Efficient” here means “solvable in polynomial time” Polynomial Time Reduction: We say that \\(F\\) reduces to \\(G\\) in polynomial time if there is a polynomial-time computable \\(R: \\{0,1\\}^* \\rightarrow \\{0,1\\}^*\\) such that for every \\(x \\in \\{0,1\\}^*, F(x) = G(R(x))\\) Notation: \\(F \\leq_p G\\) is “\\(F\\) polynomial-time reduces to \\(G\\)” 6.3 Transitivity of Polynomial Time Reductions We want to solve \\(F\\) in polynomial time I can reduce \\(F\\) to \\(G\\) (reduced 2-SAT) in \\(O(n^c)\\) time I can reduce 2-SAT to Cycle Finding in \\(O(n^k)\\) time I can solve \\(F\\) in \\(O((n^c)^k)=O(n^{ck})\\) time (still polynomial) Chained-together reductions 6.4 Procedure for showing \\(A \\leq_p B\\) We want to use \\(B\\) to solve \\(A\\) Start with an instance \\(x_a\\) of problem \\(A\\) Find an algorithm \\(R\\) to convert \\(x_a\\) into \\(x_b\\) and instance of \\(B\\) Show that \\(R\\) takes polynomial time Show that if \\(B(x_b) = 1\\) then \\(A(x_a) = 1\\) (same output) Show that if \\(B(x_b) = 0\\) then \\(A(x_a) = 0\\) (same output) More often: if \\(A(x_a) = 1\\) then \\(B(x_b) = 1\\) (contrapositive) "],["reducing-3-sat-to-longest-path.html", "7 Reducing 3-SAT to Longest Path 7.1 3-SAT \\(\\leq_p\\) Longest Path", " 7 Reducing 3-SAT to Longest Path 7.1 3-SAT \\(\\leq_p\\) Longest Path Take a 3-SAT formula Convert this into a graph If we can find the length of the longest path Solution exists if and only if there is a “long enough” path 7.1.1 Procedure Start with a 3-CNF formula \\(x_a\\) Find an algorithm \\(R\\) to convert \\(x_a\\) into a graph \\(x_b\\) Show that \\(R\\) takes polynomial time Show that if \\(3SAT(x_a) = 1\\) then \\(LP(x_b) \\geq n \\cdot m + n + 3 \\cdot m\\) Show that if \\(LP(x_b) \\geq n \\cdot m + n + 3 \\cdot m\\) then \\(3SAT(x_a) = 1\\) 7.1.2 Conclusion I really do not want to type out what he says in the video so you are welcome to go look at it yourself if you really want the explanation. Anyways, what can we conclude? If we found a polynomial time solution for Longest Path This procedure is a polynomial time solution for 3-SAT If we somehow knew that it was impossible to find a polynomial time solution for 3-SAT We could never find a polynomial time solution for Longest Path "],["longest-path-decision-problem.html", "8 Longest Path Decision Problem 8.1 Decision Problems 8.2 Longest Path: Decision Version 8.3 Using Decision Version to Solve Original", " 8 Longest Path Decision Problem 8.1 Decision Problems Decision problems are problems that have an output of a single digit, like a boolean (0 or 1). 3-SAT is a decision problem already Is the given equation satisfiable? Longest Path is not a decision problem What is the longest path from node \\(s\\) to node \\(t\\) in the given graph? 8.2 Longest Path: Decision Version Original: Given graph \\(G\\), start node \\(s\\), end node \\(t\\), what is the length of the longest path from \\(s\\) to \\(t\\)? Input: \\(G,s,t\\) Output: a number Decision: Given a graph \\(G\\), start node \\(s\\), end node \\(t\\), and a number \\(n\\), is there a path from \\(s\\) to \\(t\\) with length at least \\(n\\)? Input: \\(G,s,t,n\\) Output: 0 or 1 8.3 Using Decision Version to Solve Original If we could solve the decision version of Longest Path in polynomial time, then we can solve the original version of Longest Path in polynomial time as well. def LongestPath(G,s,t): for n in [0,|v|]: if not DecisionLongestPath(G,s,t,n): return n-1 return false Here we are trying the Decision version of the problem over and over again, increasing \\(n\\) as we go, until we find a value of \\(n\\) where there is no longer path. Then, we simply return \\(n-1\\) to get the largest path length that exists. If we can solve the Decision version in polynomial time, because this is simply the Decision version over and over again, it’s a value times a polynomial time, meaning it is solvable in polynomial time. "],["nondeterministic-turing-machines-and-the-class-np.html", "9 Nondeterministic Turing Machines and the Class NP 9.1 NP 9.2 Review: NFAs", " 9 Nondeterministic Turing Machines and the Class NP 2-SAT and Shortest Path fall under \\(P\\) (Polynomial time) Seem to be “easy” solutions Solvable in polynomial time 3-SAT and Longest Path fall under \\(EXP\\) (Exponential Time) Seem to be “hard” solutions Best known solutions require trying all possible solutions Note that \\(P\\) is a subset of \\(EXP\\). We can solve \\(P\\) problems in \\(EXP\\), but not all \\(EXP\\) problems can be solved in \\(P\\). Well, now we can add \\(NP\\). 9.1 NP \\(NP\\) = Nondeterministic Polynomial time Easy to check in polynomial time If we had a solution for 3-SAT, we can check it in polynomial time Same for checking Longest Path Solvable in polynomial time using non-determinism We actually don’t know whether \\(P\\) is a subset or proper subset (subset-equals) of \\(NP\\) (Millennium problems!). 9.2 Review: NFAs There is only ever one option of what we can do in a deterministic finite state automata. In non-determinism, we have many options. 9.2.1 How to think about non-determinism Omnipotence: The machine can be in multiple states at the same time “Parallelism” Omniscience: Whenever there is a choice, the machine always picks the right/best one “Witness” 9.2.2 Non-Deterministic Turing Machines We have a tape to keep track of. This means that we have an iterator that can look around in the tape. This means that we can return 1 if any configuration ended in an accept state. Compare this to a deterministic Turing machine, where it returns 1 if in an accept state and 0 otherwise. "],["why-do-we-care-whether-p-np.html", "10 Why do we care whether \\(P = NP\\)?", " 10 Why do we care whether \\(P = NP\\)? If \\(P = NP\\), we can really solve anything with computers If \\(P \\neq NP\\), security as we know is is fucking gone. lolllllll "],["np-completeness.html", "11 NP Completeness 11.1 NP-Hard", " 11 NP Completeness Problems solvable in polynomial time if and only if all \\(NP\\) problems are \\(NP\\)-Complete = \\(NP \\cap NP\\)-Hard How do you show a problem is \\(NP\\)-Complete? Show it belongs to \\(NP\\) Give a polynomial time verifier Show it is \\(NP\\)-Hard Give a reduction from another \\(NP\\)-Hard problem …We just need a first \\(NP\\)-Hard problem 11.1 NP-Hard Absolutely all can solve in polynomial problems, or none can: “Together they stand, together they fall” How can we try to figure out if \\(P = NP\\)? Identify problems at least as “hard” as \\(NP\\) If any of these “hard” problems can be solved in polynomial time, then all \\(NP\\) problems can be solved in polynomial time Definition of \\(NP\\)-Hard: \\(B\\) is \\(NP\\)-Hard if \\(\\forall A \\in NP, A \\leq_p B\\) \\(A \\leq_p B\\) means \\(A\\) reduces to \\(B\\) in polynomial time "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
